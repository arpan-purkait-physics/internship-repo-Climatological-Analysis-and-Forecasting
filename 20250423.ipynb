{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f9436f-7f93-4b36-8f5d-541491a30ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imdlib\n",
      "  Downloading imdlib-0.1.20-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.12/site-packages (from imdlib) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.12/site-packages (from imdlib) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2.2.2)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.12/site-packages (from imdlib) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2024.1)\n",
      "Requirement already satisfied: urllib3 in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2.2.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.12/site-packages (from imdlib) (1.13.1)\n",
      "Requirement already satisfied: xarray in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2023.6.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.12/site-packages (from imdlib) (2.32.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/lib/python3.12/site-packages (from pandas->imdlib) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.12/site-packages (from requests->imdlib) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.12/site-packages (from requests->imdlib) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.12/site-packages (from requests->imdlib) (2025.1.31)\n",
      "Downloading imdlib-0.1.20-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: imdlib\n",
      "Successfully installed imdlib-0.1.20\n"
     ]
    }
   ],
   "source": [
    "! pip install imdlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f9a041-6e85-438a-a667-16ff6b59f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdlib as imd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd6f3de-ea90-4e4b-ad19-284ac416f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: rain for year 1990\n",
      "Downloading: rain for year 1991\n",
      "Downloading: rain for year 1992\n",
      "Downloading: rain for year 1993\n",
      "Downloading: rain for year 1994\n",
      "Downloading: rain for year 1995\n",
      "Downloading: rain for year 1996\n",
      "Downloading: rain for year 1997\n",
      "Downloading: rain for year 1998\n",
      "Downloading: rain for year 1999\n",
      "Downloading: rain for year 2000\n",
      "Downloading: rain for year 2001\n",
      "Downloading: rain for year 2002\n",
      "Downloading: rain for year 2003\n",
      "Downloading: rain for year 2004\n",
      "Downloading: rain for year 2005\n",
      "Downloading: rain for year 2006\n",
      "Downloading: rain for year 2007\n",
      "Downloading: rain for year 2008\n",
      "Downloading: rain for year 2009\n",
      "Downloading: rain for year 2010\n",
      "Downloading: rain for year 2011\n",
      "Downloading: rain for year 2012\n",
      "Downloading: rain for year 2013\n",
      "Downloading: rain for year 2014\n",
      "Downloading: rain for year 2015\n",
      "Downloading: rain for year 2016\n",
      "Downloading: rain for year 2017\n",
      "Downloading: rain for year 2018\n",
      "Downloading: rain for year 2019\n",
      "Downloading: rain for year 2020\n",
      "Download Successful !!!\n",
      "Downloading: maxtemp for year 1990\n",
      "Downloading: maxtemp for year 1991\n",
      "Downloading: maxtemp for year 1992\n",
      "Downloading: maxtemp for year 1993\n",
      "Downloading: maxtemp for year 1994\n",
      "Downloading: maxtemp for year 1995\n",
      "Downloading: maxtemp for year 1996\n",
      "Downloading: maxtemp for year 1997\n",
      "Downloading: maxtemp for year 1998\n",
      "Downloading: maxtemp for year 1999\n",
      "Downloading: maxtemp for year 2000\n",
      "Downloading: maxtemp for year 2001\n",
      "Downloading: maxtemp for year 2002\n",
      "Downloading: maxtemp for year 2003\n",
      "Downloading: maxtemp for year 2004\n",
      "Downloading: maxtemp for year 2005\n",
      "Downloading: maxtemp for year 2006\n",
      "Downloading: maxtemp for year 2007\n",
      "Downloading: maxtemp for year 2008\n",
      "Downloading: maxtemp for year 2009\n",
      "Downloading: maxtemp for year 2010\n",
      "Downloading: maxtemp for year 2011\n",
      "Downloading: maxtemp for year 2012\n",
      "Downloading: maxtemp for year 2013\n",
      "Downloading: maxtemp for year 2014\n",
      "Downloading: maxtemp for year 2015\n",
      "Downloading: maxtemp for year 2016\n",
      "Downloading: maxtemp for year 2017\n",
      "Downloading: maxtemp for year 2018\n",
      "Downloading: maxtemp for year 2019\n",
      "Downloading: maxtemp for year 2020\n",
      "Download Successful !!!\n",
      "Downloading: mintemp for year 1990\n",
      "Downloading: mintemp for year 1991\n",
      "Downloading: mintemp for year 1992\n",
      "Downloading: mintemp for year 1993\n",
      "Downloading: mintemp for year 1994\n",
      "Downloading: mintemp for year 1995\n",
      "Downloading: mintemp for year 1996\n",
      "Downloading: mintemp for year 1997\n",
      "Downloading: mintemp for year 1998\n",
      "Downloading: mintemp for year 1999\n",
      "Downloading: mintemp for year 2000\n",
      "Downloading: mintemp for year 2001\n",
      "Downloading: mintemp for year 2002\n",
      "Downloading: mintemp for year 2003\n",
      "Downloading: mintemp for year 2004\n",
      "Downloading: mintemp for year 2005\n",
      "Downloading: mintemp for year 2006\n",
      "Downloading: mintemp for year 2007\n",
      "Downloading: mintemp for year 2008\n",
      "Downloading: mintemp for year 2009\n",
      "Downloading: mintemp for year 2010\n",
      "Downloading: mintemp for year 2011\n",
      "Downloading: mintemp for year 2012\n",
      "Downloading: mintemp for year 2013\n",
      "Downloading: mintemp for year 2014\n",
      "Downloading: mintemp for year 2015\n",
      "Downloading: mintemp for year 2016\n",
      "Downloading: mintemp for year 2017\n",
      "Downloading: mintemp for year 2018\n",
      "Downloading: mintemp for year 2019\n",
      "Downloading: mintemp for year 2020\n",
      "Download Successful !!!\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/arpan/imd_repo\"\n",
    "variables = ['rain', 'tmax', 'tmin']\n",
    "data_ = {}\n",
    "start_yr = 1990\n",
    "end_yr = 2020\n",
    "for var in variables:\n",
    "    data_[var] = imd.get_data(var, start_yr, end_yr, fn_format='yearwise', file_dir=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68c18321-73a9-4b38-9842-c27e8a71af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 11323, lat: 31, lon: 31)\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 7.5 8.5 9.5 10.5 11.5 ... 33.5 34.5 35.5 36.5 37.5\n",
      "  * lon      (lon) float64 67.5 68.5 69.5 70.5 71.5 ... 93.5 94.5 95.5 96.5 97.5\n",
      "  * time     (time) datetime64[ns] 1990-01-01 1990-01-02 ... 2020-12-31\n",
      "Data variables:\n",
      "    tmax     (time, lat, lon) float64 99.9 99.9 99.9 99.9 ... 99.9 99.9 99.9\n",
      "Attributes:\n",
      "    Conventions:  CF-1.7\n",
      "    title:        IMD gridded data\n",
      "    source:       https://imdpune.gov.in/\n",
      "    history:      2025-04-23 18:19:20.961796 Python\n",
      "    references:   \n",
      "    comment:      \n",
      "    crs:          epsg:4326\n",
      "5\n",
      "4\n",
      "[(21.5, 85.5), (21.5, 86.5), (21.5, 87.5), (21.5, 88.5), (22.5, 85.5), (22.5, 86.5), (22.5, 87.5), (22.5, 88.5), (23.5, 85.5), (23.5, 86.5), (23.5, 87.5), (23.5, 88.5), (24.5, 85.5), (24.5, 86.5), (24.5, 87.5), (24.5, 88.5), (25.5, 85.5), (25.5, 86.5), (25.5, 87.5), (25.5, 88.5)]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "data2 = imd.open_data('tmax', start_yr, end_yr, fn_format='yearwise', file_dir=path)\n",
    "ds2 = data2.get_xarray()\n",
    "print(ds2)\n",
    "import numpy as np\n",
    "lat_list = np.arange(21.5, 26.5, 1)  # 21.5 to 25.5\n",
    "lon_list = np.arange(85.5, 89.5, 1)  # 85.5 to 89.5\n",
    "print(len(lat_list))\n",
    "print(len(lon_list))\n",
    "lat_lon_pairs = [(float(lat), float(lon)) for lat in lat_list for lon in lon_list]\n",
    "print(lat_lon_pairs)\n",
    "print(len(lat_lon_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d260b0ec-938f-458f-9dd7-0e2fb9ff6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"/home/arpan/imd_repo/broken_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4639a714-fa9a-41a1-9335-66ae2f2a5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lat, lon in lat_lon_pairs:\n",
    "  file_name = f\"tmax_{lat}_{lon}.csv\"\n",
    "  data2.to_csv(file_name, lat, lon, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19a7a443-af33-4094-9226-435be50b6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = imd.open_data('tmin', start_yr, end_yr, fn_format='yearwise', file_dir=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a5fa9bd-7ab7-4bc5-b121-45141c3ecc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = imd.open_data('rain', start_yr, end_yr, fn_format='yearwise', file_dir=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7b6a96f-bb00-4de9-afad-2f97fc4128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "799adb0a-3489-40c3-887b-c2faf4619a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as 'merged_data_tmax.csv'\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(path2, \"tmax*\"))\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)  # Read CSV file\n",
    "\n",
    "    # Extract latitude and longitude from the second column name\n",
    "    lat_lon = df.columns[1]  # The second column has lat lon\n",
    "    df.columns = [\"DateTime\", f\"{lat_lon.replace(' ', '_')}\"]  # Rename columns\n",
    "\n",
    "    dfs.append(df)\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=\"DateTime\", how=\"outer\")\n",
    "merged_df.to_csv(\"tmax.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV saved as 'merged_data_tmax.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17905e3e-5396-48c8-9225-ec1f51dfbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as 'merged_data_tmin.csv'\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(path2, \"tmin*\"))\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)  # Read CSV file\n",
    "\n",
    "    # Extract latitude and longitude from the second column name\n",
    "    lat_lon = df.columns[1]  # The second column has lat lon\n",
    "    df.columns = [\"DateTime\", f\"{lat_lon.replace(' ', '_')}\"]  # Rename columns\n",
    "\n",
    "    dfs.append(df)\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=\"DateTime\", how=\"outer\")\n",
    "merged_df.to_csv(\"tmin.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV saved as 'merged_data_tmin.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb8c629c-08ce-4988-8851-48db6ee1aa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as 'merged_data_rain.csv'\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(path2, \"rain*\"))\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file)  # Read CSV file\n",
    "\n",
    "    # Extract latitude and longitude from the second column name\n",
    "    lat_lon = df.columns[1]  # The second column has lat lon\n",
    "    df.columns = [\"DateTime\", f\"{lat_lon.replace(' ', '_')}\"]  # Rename columns\n",
    "\n",
    "    dfs.append(df)\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=\"DateTime\", how=\"outer\")\n",
    "merged_df.to_csv(\"rain.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV saved as 'merged_data_rain.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d33086d8-7377-44c0-81b7-0417a0c282b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6026763b-cdd8-4b70-8efe-bbf26cb1c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wide format file\n",
    "df = pd.read_csv('rain.csv')\n",
    "\n",
    "# Melt the dataframe to long format\n",
    "df_long = df.melt(id_vars=['DateTime'], var_name='Lat_Lon', value_name='rain')\n",
    "\n",
    "# Split 'Lat_Lon' into 'Latitude' and 'Longitude'\n",
    "df_long[['Latitude', 'Longitude']] = df_long['Lat_Lon'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the original 'Lat_Lon' column\n",
    "df_long.drop(columns='Lat_Lon', inplace=True)\n",
    "\n",
    "# Reorder columns and convert to proper types\n",
    "df_long = df_long[['DateTime', 'Latitude', 'Longitude', 'rain']]\n",
    "df_long.rename(columns={'DateTime': 'Date'}, inplace=True)\n",
    "df_long['Latitude'] = df_long['Latitude'].astype(float)\n",
    "df_long['Longitude'] = df_long['Longitude'].astype(float)\n",
    "df_long['rain'] = pd.to_numeric(df_long['rain'], errors='coerce')  # Handle '99.9' etc.\n",
    "\n",
    "# Optionally filter out bad values like 99.9 (if they are missing data)\n",
    "#df_long = df_long[df_long['rain'] < 60]\n",
    "\n",
    "# Save the long format CSV\n",
    "df_long.to_csv('formated_rain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbf43162-a3f7-4628-95ec-977a99be340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wide format file\n",
    "df = pd.read_csv('tmax.csv')\n",
    "\n",
    "# Melt the dataframe to long format\n",
    "df_long = df.melt(id_vars=['DateTime'], var_name='Lat_Lon', value_name='tmax')\n",
    "\n",
    "# Split 'Lat_Lon' into 'Latitude' and 'Longitude'\n",
    "df_long[['Latitude', 'Longitude']] = df_long['Lat_Lon'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the original 'Lat_Lon' column\n",
    "df_long.drop(columns='Lat_Lon', inplace=True)\n",
    "\n",
    "# Reorder columns and convert to proper types\n",
    "df_long = df_long[['DateTime', 'Latitude', 'Longitude', 'tmax']]\n",
    "df_long.rename(columns={'DateTime': 'Date'}, inplace=True)\n",
    "df_long['Latitude'] = df_long['Latitude'].astype(float)\n",
    "df_long['Longitude'] = df_long['Longitude'].astype(float)\n",
    "df_long['tmax'] = pd.to_numeric(df_long['tmax'], errors='coerce')  # Handle '99.9' etc.\n",
    "\n",
    "# Optionally filter out bad values like 99.9 (if they are missing data)\n",
    "#df_long = df_long[df_long['rain'] < 60]\n",
    "\n",
    "# Save the long format CSV\n",
    "df_long.to_csv('formated_tmax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29bf1737-ec13-49b3-b8b0-c3ffd361e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wide format file\n",
    "df = pd.read_csv('tmin.csv')\n",
    "\n",
    "# Melt the dataframe to long format\n",
    "df_long = df.melt(id_vars=['DateTime'], var_name='Lat_Lon', value_name='tmin')\n",
    "\n",
    "# Split 'Lat_Lon' into 'Latitude' and 'Longitude'\n",
    "df_long[['Latitude', 'Longitude']] = df_long['Lat_Lon'].str.split('_', expand=True)\n",
    "\n",
    "# Drop the original 'Lat_Lon' column\n",
    "df_long.drop(columns='Lat_Lon', inplace=True)\n",
    "\n",
    "# Reorder columns and convert to proper types\n",
    "df_long = df_long[['DateTime', 'Latitude', 'Longitude', 'tmin']]\n",
    "df_long.rename(columns={'DateTime': 'Date'}, inplace=True)\n",
    "df_long['Latitude'] = df_long['Latitude'].astype(float)\n",
    "df_long['Longitude'] = df_long['Longitude'].astype(float)\n",
    "df_long['tmin'] = pd.to_numeric(df_long['tmin'], errors='coerce')  # Handle '99.9' etc.\n",
    "\n",
    "# Optionally filter out bad values like 99.9 (if they are missing data)\n",
    "#df_long = df_long[df_long['rain'] < 60]\n",
    "\n",
    "# Save the long format CSV\n",
    "df_long.to_csv('formated_tmin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e8562b7-a789-43b5-bfac-6515f40fb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the long-format CSVs\n",
    "tmin_df = pd.read_csv('formated_tmin.csv')\n",
    "tmax_df = pd.read_csv('formated_tmax.csv')\n",
    "rain_df = pd.read_csv('formated_rain.csv')\n",
    "\n",
    "# Rename value columns to distinguish them\n",
    "tmin_df.rename(columns={'Tmin': 'Tmin'}, inplace=True)\n",
    "tmax_df.rename(columns={'Tmax': 'Tmax'}, inplace=True)\n",
    "rain_df.rename(columns={'Rain': 'Rain'}, inplace=True)\n",
    "\n",
    "# Merge Tmin and Tmax\n",
    "merged_df = pd.merge(tmin_df, tmax_df, on=['Date', 'Latitude', 'Longitude'])\n",
    "\n",
    "# Merge the result with Rain\n",
    "merged_df = pd.merge(merged_df, rain_df, on=['Date', 'Latitude', 'Longitude'])\n",
    "\n",
    "merged_df.to_csv('merged_climate_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
